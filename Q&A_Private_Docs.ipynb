{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q & A on private documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages\\llama-0.0.1-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages\\llama-0.0.1-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/ae/59/911d6e5f1d7514d79c527067643376cddcf4cb8d1728e599b3b03ab51c69/openai-0.28.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.5 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/76.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.5/76.5 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from tiktoken) (2023.8.8)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages\\llama-0.0.1-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "! pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pinecone-client) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pinecone-client) (6.0.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pinecone-client) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pinecone-client) (4.7.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pinecone-client) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pinecone-client) (1.26.16)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pinecone-client) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pinecone-client) (1.25.2)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages\\llama-0.0.1-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "! pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 932a7998-263d-49be-86c6-54eba5a99ec0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, WikipediaLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import tiktoken\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'),environment=os.environ.get('PINECONE_ENV'))\n",
    "print(\"a\",os.environ.get('PINECONE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages\\llama-0.0.1-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "! pip install pypdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (0.0.279)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from langchain) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from langchain) (0.0.32)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from langchain) (2.8.5)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from langchain) (2.3.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages\\llama-0.0.1-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file):\n",
    "\n",
    "    name, extension = os.path.splitext(file)\n",
    "\n",
    "    if extension == '.pdf' :\n",
    "        print(f'Loading {file}')\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == '.docx':\n",
    "        print(f'Loading {file}')\n",
    "        loader = Docx2txtLoader(file)\n",
    "    else:\n",
    "        print(f\"Document format {extension} is not supported!\")\n",
    "        \n",
    "    # print(data[1].page_content)\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "def load_from_wikipedia(query, lang='en', load_max_docs=2):\n",
    "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data,chunk_size=256):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=0)\n",
    "    chunks=text_splitter.split_documents(data)\n",
    "    return chunks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embeddings_cost(texts):\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts] )\n",
    "    print(f'Total Token: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens/1000 * 0.0004:.6f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name):\n",
    "\n",
    "    embeddings=OpenAIEmbeddings()\n",
    "    \n",
    "\n",
    "    if index_name in pinecone.list_indexes():\n",
    "        print(f'index {index_name} already exists. Loading embeddings ...',end='')\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print('ok')\n",
    "    else:\n",
    "        print(f'Creating index {index_name} and embeddings ...',end='')\n",
    "        pinecone.create_index(index_name, dimension=1536,metric='cosine')\n",
    "        vector_store=Pinecone.from_documents(chunks,embeddings,index_name=index_name)\n",
    "        print('ok')\n",
    "\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name='all'):\n",
    "\n",
    "    if index_name=='all':\n",
    "        indexes = pinecone.list_indexes()\n",
    "        print(\"Deleting allll indexes....\")\n",
    "        for index in indexes:\n",
    "            pinecone.delete_index(index)\n",
    "        print(\"ok\")\n",
    "\n",
    "    else:\n",
    "        print(f'Deleting index {index_name} ...', end='')\n",
    "        pinecone.delete_index(index_name)\n",
    "        print('ok')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./data/SwinUnet.pdf\n",
      "There are 14 pages in the pdf document\n"
     ]
    }
   ],
   "source": [
    "## Running code\n",
    "data = load_document('./data/SwinUnet.pdf')\n",
    "# data = load_document('./Llama2_QuamtizedRun.ipynb')\n",
    "# print(data[1].page_content)\n",
    "# print(data[10].metadata)\n",
    "\n",
    "print(f'There are {len(data)} pages in the pdf document')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "$$$$$\n",
      "neural networks based on U-shaped architecture and skip-connections\n",
      "have been widely applied in a variety of medical image tasks. How-\n",
      "ever, although CNN has achieved excellent performance, it cannot learn\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_data(data)\n",
    "print(len(chunks))\n",
    "print(\"$$$$$\")\n",
    "print(chunks[2].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Token: 9383\n",
      "Embedding Cost in USD: 0.003753\n"
     ]
    }
   ],
   "source": [
    "print_embeddings_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting allll indexes....\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index askswinunet and embeddings ..."
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "VectorStore.from_documents() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m index_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39maskswinunet\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m vector_store \u001b[39m=\u001b[39m insert_or_fetch_embeddings(index_name)\n",
      "Cell \u001b[1;32mIn[37], line 13\u001b[0m, in \u001b[0;36minsert_or_fetch_embeddings\u001b[1;34m(index_name)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCreating index \u001b[39m\u001b[39m{\u001b[39;00mindex_name\u001b[39m}\u001b[39;00m\u001b[39m and embeddings ...\u001b[39m\u001b[39m'\u001b[39m,end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m     pinecone\u001b[39m.\u001b[39mcreate_index(index_name, dimension\u001b[39m=\u001b[39m\u001b[39m1536\u001b[39m,metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcosine\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     vector_store\u001b[39m=\u001b[39mPinecone\u001b[39m.\u001b[39;49mfrom_documents(chunks,embeddings,index_name)\n\u001b[0;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mok\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m vector_store\n",
      "\u001b[1;31mTypeError\u001b[0m: VectorStore.from_documents() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "index_name = 'askswinunet'\n",
    "vector_store = insert_or_fetch_embeddings(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\nisha\\miniconda3\\envs\\llama2conda\\lib\\site-packages\\llama-0.0.1-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "! pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its series of GPT foundation models. It was initially released on March 14, 2023, and has been made publicly available via the paid chatbot product ChatGPT Plus, and via OpenAI's API.  As a transformer-based model, GPT-4 uses a paradigm where pre-training using both public data and \"data licensed from third-party providers\" is used to predict the next token. After this step, the model was then fine-tuned with reinforcement learning feedback from humans and AI for human alignment and policy compliance.: 2 Observers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous iteration based on GPT-3.5, with the caveat that GPT-4 retains some of the problems with earlier revisions. GPT-4 is also capable of taking images as input, though this feature has not been made available since launch. OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model.\n",
      "\n",
      "\n",
      "== Background ==\n",
      " \n",
      "OpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\" It was based on the transformer architecture and trained on a large corpus of books. The next year, they introduced GPT-2, a larger model that could generate coherent text. In 2020, they introduced GPT-3, a model with 100 times as many parameters as GPT-2, that could perform various tasks with few examples. GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT.\n",
      "Rumors claim that GPT-4 has 1.76 trillion parameters, which was first estimated by the speed it was running and by George Hotz.\n",
      "\n",
      "\n",
      "== Capabilities ==\n",
      "OpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\" They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively. Some of the capabilities of GPT-4 were predicted by OpenAI before training it, although other capabilities remained hard to predict due to breaks in downstream scaling laws. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input; this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams.To gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.When instructed to do so, GPT-4 can interact with external interfaces. For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model's prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.A 2023 article in Nature stated programmers have found GPT-4 useful for assisting in coding tasks (despite its propensity for error), such as finding errors in existing code and suggesting optimizations to improve performance. The article quoted a biophysicist who found that the time he required to port one of his programs from MATLAB to Python went down from days to \"an hou\n"
     ]
    }
   ],
   "source": [
    "data = load_from_wikipedia('GPT-4')\n",
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
