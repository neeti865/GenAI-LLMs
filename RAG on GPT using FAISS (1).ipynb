{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b10a6beb",
   "metadata": {},
   "source": [
    "# RAG with GPT using FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe1a14",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5cd7ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q transformers einops accelerate langchain bitsandbytes pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e5f61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\anaconda3\\lib\\site-packages (0.0.27)\n",
      "Requirement already satisfied: pydantic in c:\\anaconda3\\lib\\site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from langchain) (1.21.6)\n",
      "Requirement already satisfied: sqlalchemy in c:\\anaconda3\\lib\\site-packages (from langchain) (1.3.1)\n",
      "Requirement already satisfied: pyyaml in c:\\anaconda3\\lib\\site-packages (from langchain) (5.1)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from langchain) (2.21.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\anaconda3\\lib\\site-packages (from pydantic->langchain) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\anaconda3\\lib\\site-packages (from pydantic->langchain) (0.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\anaconda3\\lib\\site-packages (from pydantic->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->langchain) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->langchain) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->langchain) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\anaconda3\\lib\\site-packages (from requests->langchain) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbdd36f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\anaconda3\\lib\\site-packages (1.7.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92aa9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain[all] in c:\\anaconda3\\lib\\site-packages (0.0.27)\n",
      "Requirement already satisfied: pyyaml in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (5.1)\n",
      "Requirement already satisfied: pydantic in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (2.4.2)\n",
      "Requirement already satisfied: sqlalchemy in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (1.3.1)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (1.21.6)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (2.21.0)\n",
      "Requirement already satisfied: cohere; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (4.31)\n",
      "Requirement already satisfied: wikipedia; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (1.4.0)\n",
      "Requirement already satisfied: spacy; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (3.7.2)\n",
      "Requirement already satisfied: openai; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (0.27.8)\n",
      "Requirement already satisfied: huggingface-hub; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (0.16.4)\n",
      "Requirement already satisfied: google-search-results; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (2.4.2)\n",
      "Requirement already satisfied: nltk; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (3.4)\n",
      "Requirement already satisfied: nlpcloud; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (1.1.44)\n",
      "Requirement already satisfied: sentence-transformers; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (2.2.2)\n",
      "Requirement already satisfied: elasticsearch; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (8.10.1)\n",
      "Requirement already satisfied: transformers; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (4.30.2)\n",
      "Requirement already satisfied: faiss-cpu; extra == \"all\" in c:\\anaconda3\\lib\\site-packages (from langchain[all]) (1.7.4)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\anaconda3\\lib\\site-packages (from pydantic->langchain[all]) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\anaconda3\\lib\\site-packages (from pydantic->langchain[all]) (4.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\anaconda3\\lib\\site-packages (from pydantic->langchain[all]) (0.5.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\anaconda3\\lib\\site-packages (from requests->langchain[all]) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->langchain[all]) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->langchain[all]) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->langchain[all]) (2.8)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in c:\\anaconda3\\lib\\site-packages (from cohere; extra == \"all\"->langchain[all]) (6.7.0)\n",
      "Requirement already satisfied: fastavro==1.7.4; python_version >= \"3.7\" and python_version < \"3.8\" in c:\\anaconda3\\lib\\site-packages (from cohere; extra == \"all\"->langchain[all]) (1.7.4)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in c:\\anaconda3\\lib\\site-packages (from cohere; extra == \"all\"->langchain[all]) (3.8.5)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in c:\\anaconda3\\lib\\site-packages (from cohere; extra == \"all\"->langchain[all]) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\anaconda3\\lib\\site-packages (from wikipedia; extra == \"all\"->langchain[all]) (4.7.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (6.4.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (0.3.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (2.4.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (1.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (4.66.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (0.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (40.8.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (1.1.2)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda3\\lib\\site-packages (from spacy; extra == \"all\"->langchain[all]) (2.10)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from huggingface-hub; extra == \"all\"->langchain[all]) (3.0.10)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda3\\lib\\site-packages (from huggingface-hub; extra == \"all\"->langchain[all]) (2023.1.0)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from nltk; extra == \"all\"->langchain[all]) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\anaconda3\\lib\\site-packages (from nltk; extra == \"all\"->langchain[all]) (3.4.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda3\\lib\\site-packages (from sentence-transformers; extra == \"all\"->langchain[all]) (0.20.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\anaconda3\\lib\\site-packages (from sentence-transformers; extra == \"all\"->langchain[all]) (1.13.1)\n",
      "Requirement already satisfied: torchvision in c:\\anaconda3\\lib\\site-packages (from sentence-transformers; extra == \"all\"->langchain[all]) (0.14.1)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from sentence-transformers; extra == \"all\"->langchain[all]) (1.2.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\anaconda3\\lib\\site-packages (from sentence-transformers; extra == \"all\"->langchain[all]) (0.1.99)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in c:\\anaconda3\\lib\\site-packages (from elasticsearch; extra == \"all\"->langchain[all]) (8.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda3\\lib\\site-packages (from transformers; extra == \"all\"->langchain[all]) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\anaconda3\\lib\\site-packages (from transformers; extra == \"all\"->langchain[all]) (0.4.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\anaconda3\\lib\\site-packages (from transformers; extra == \"all\"->langchain[all]) (0.13.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\anaconda3\\lib\\site-packages (from importlib_metadata<7.0,>=6.0->cohere; extra == \"all\"->langchain[all]) (3.15.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere; extra == \"all\"->langchain[all]) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere; extra == \"all\"->langchain[all]) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere; extra == \"all\"->langchain[all]) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere; extra == \"all\"->langchain[all]) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere; extra == \"all\"->langchain[all]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere; extra == \"all\"->langchain[all]) (19.1.0)\n",
      "Requirement already satisfied: asynctest==0.13.0; python_version < \"3.8\" in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere; extra == \"all\"->langchain[all]) (0.13.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere; extra == \"all\"->langchain[all]) (1.3.3)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia; extra == \"all\"->langchain[all]) (1.8)\n",
      "Requirement already satisfied: confection<0.2.0,>=0.0.4 in c:\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy; extra == \"all\"->langchain[all]) (0.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy; extra == \"all\"->langchain[all]) (0.16.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy; extra == \"all\"->langchain[all]) (0.4.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy; extra == \"all\"->langchain[all]) (8.1.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy; extra == \"all\"->langchain[all]) (0.7.11)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda3\\lib\\site-packages (from jinja2->spacy; extra == \"all\"->langchain[all]) (1.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers; extra == \"all\"->langchain[all]) (5.4.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "949fd25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\anaconda3\\lib\\site-packages (4.30.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.16.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.21.6)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.21.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.0.10)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (5.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9; extra == \"torch\" in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: accelerate>=0.20.2; extra == \"torch\" in c:\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.7.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->transformers[torch]) (3.15.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.1)\n",
      "Requirement already satisfied: psutil in c:\\anaconda3\\lib\\site-packages (from accelerate>=0.20.2; extra == \"torch\"->transformers[torch]) (5.6.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db38a43b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m \u001b[39mimport\u001b[39;00m HuggingFacePipeline\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m cuda\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "import transformers\n",
    "import torch\n",
    "from torch import cuda\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff176f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "### Initializing Huggingface embedding pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d9168",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a6f3d",
   "metadata": {},
   "source": [
    "### Define Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e6b2615",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cuda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m embed_model_id \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[39m'\u001b[39m \u001b[39m## 384\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m device \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda:\u001b[39m\u001b[39m{\u001b[39;00mcuda\u001b[39m.\u001b[39mcurrent_device()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m cuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUtilizing : \u001b[39m\u001b[39m{\u001b[39;00mdevice\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m embed_model \u001b[39m=\u001b[39m HuggingFaceEmbeddings(\n\u001b[0;32m      7\u001b[0m     model_name\u001b[39m=\u001b[39membed_model_id,\n\u001b[0;32m      8\u001b[0m     model_kwargs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m: device},\n\u001b[0;32m      9\u001b[0m     encode_kwargs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m: device, \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m32\u001b[39m}\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cuda' is not defined"
     ]
    }
   ],
   "source": [
    "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2' ## 384\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "print(f'Utilizing : {device}')\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_id,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': 32}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17825d60",
   "metadata": {},
   "source": [
    "### Setting up Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e0d695",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader('./data/paper-2023.05.pdf')\n",
    "\n",
    "documents = loader.load()\n",
    "print(f'length of docs {len(documents)}')\n",
    "print(documents[12])\n",
    "## Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(len(texts))\n",
    "print('*********************************',texts[1].page_content)\n",
    "print(\"%%%%%%%%%\",texts[0].metadata['source'].split('-')[1])\n",
    "\n",
    "# df = pd.DataFrame(columns=['chunk','chunkid','docid'])\n",
    "rows=[]\n",
    "\n",
    "for idx in range(len(texts)):\n",
    "    rows.append([texts[idx].page_content,idx, texts[0].metadata['source'].split('-')[1]])\n",
    "\n",
    "print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "print(rows[1])\n",
    "print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "df1 = pd.DataFrame(rows, columns=['chunk', 'chunkid', 'docid'])\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efff00d",
   "metadata": {},
   "source": [
    "### Building Vector Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20330414",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656a9bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "! pip install faiss-cpu #pip install pinecone-client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2edb9f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def build_index(data):\n",
    "    vectors= generate_encodings(data)\n",
    "    vector_dimension = vectors.shape[1]\n",
    "    index = faiss.IndexFlatL2(vector_dimension)\n",
    "    faiss.normalize_L2(vectors)\n",
    "    index.add(vectors)\n",
    "\n",
    "def save_index(index):\n",
    "    faiss.write_index(index)\n",
    "\n",
    "def generate_encodings(text):\n",
    "    vectors =  embed_model.embed_documents(text)\n",
    "    return vectors\n",
    "\n",
    "def load_index(f_path):\n",
    "    index = faiss.read_index(f_path)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b461deea",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f0178",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "db = FAISS.from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69a66b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def get_vectors(df1=None,batch_size=32,):\n",
    "#     batch_size = 32\n",
    "    print(len(df1))\n",
    "    for i in range(0, len(df1), batch_size):\n",
    "        i_end = min(len(df1), i+batch_size)\n",
    "        batch = df1.iloc[i:i_end]\n",
    "        ids = [f\"{x['docid']}-{x['chunkid']}\" for i, x in batch.iterrows()]\n",
    "        texts = [x['chunk'] for i, x in batch.iterrows()]\n",
    "        embeds = embed_model.embed_documents(texts)\n",
    "        # get metadata to store in Pinecone\n",
    "        metadata = [\n",
    "            {'text': x['chunk'],\n",
    "            #  'source': x['source'],\n",
    "            #  'title': x['title']\n",
    "             } for i, x in batch.iterrows()\n",
    "        ]\n",
    "        # add to Pinecone\n",
    "        print(f\"embeddings total {len(embeds)} eith a dimensionality of {len(embeds[0])}\")\n",
    "        vectors=list(zip(ids, embeds, metadata))\n",
    "        print(\"55555555555555555555555555555555555555\")\n",
    "        print(vectors[1])\n",
    "        \n",
    "    return vectors\n",
    "\n",
    "vec_raw = get_vectors(df1)\n",
    "\n",
    "# vector_store = FAISS.from_embeddings(\n",
    "vector_store = FAISS.from_text(\n",
    "    vec_raw,\n",
    "    embedding = embed_model\n",
    ")\n",
    "\n",
    "##  persist\n",
    "vector_store.save_local(\"faiss_rag_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99089533",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "db = FAISS.load_local(\"faiss_rag_index\",embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7d173",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "documents = db.similarity_search(query=\"What is DiffTF?\",k=3)\n",
    "print(documents)\n",
    "\n",
    "query = 'Explain DiffTF'\n",
    "\n",
    "db.similarity_search(\n",
    "    query,  # the search query\n",
    "    k=3  # returns top 3 most relevant chunks of text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409abaa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "print(len(df1))\n",
    "for i in range(0, len(df1), batch_size):\n",
    "    i_end = min(len(df1), i+batch_size)\n",
    "    batch = df1.iloc[i:i_end]\n",
    "    ids = [f\"{x['docid']}-{x['chunkid']}\" for i, x in batch.iterrows()]\n",
    "    texts = [x['chunk'] for i, x in batch.iterrows()]\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'text': x['chunk'],\n",
    "        #  'source': x['source'],\n",
    "        #  'title': x['title']\n",
    "         } for i, x in batch.iterrows()\n",
    "    ]\n",
    "    # add to Pinecone\n",
    "    print(f\"embeddings total {len(embeds)} eith a dimensionality of {len(embeds[0])}\")\n",
    "    vectors=list(zip(ids, embeds, metadata))\n",
    "    print(\"55555555555555555555555555555555555555\")\n",
    "#     print(vectors)\n",
    "    \n",
    "    \n",
    "#     print(\"##################meta data \",metadata)\n",
    "#     print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% embeds\",embeds)\n",
    " \n",
    "#     index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8878c83",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "### BUilding the LLM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108d449",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463c76a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "#meta-llama/Llama-2-7b-h\n",
    "model_id = 'meta-llama/Llama-2-7b-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    # use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    # use_auth_token=hf_auth\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e0eb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    # use_auth_token=hf_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9fee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    # we pass model parameters here too\n",
    "    temperature=0.0,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "    do_sample=False,\n",
    "    max_new_tokens=512,  # mex number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # without this output begins repeating\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa88273",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "### Initialize the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6008aac",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c392f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = 'text'  # field in metadata that contains text content\n",
    "\n",
    "vectorstore = FAISS.load_local(\"faiss_rag_index\", embed_model.embed_query,text_field )\n",
    "# vectorstore = Pinecone(\n",
    "#     index, embed_model.embed_query, text_field\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ea5a07",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "rag_pipeline = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type='stuff',\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4c889",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "query = 'Explain DiffTF'\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query,  # the search query\n",
    "    k=3  # returns top 3 most relevant chunks of text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e958d43e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "llm('Explain DiffTF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f599e57",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "rag_pipeline('Explain DiffTF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeadc0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pcc-env' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n pcc-env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "21b00a7e5d6f4a24e0e0a931d47cda92a2fabf7ec51f81f5bd92e232aed18181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
